
# ğŸ¬ Movie Genre Labelling Based on Poster and Title

This project explores a multimodal deep learning approach for automatically classifying movie genres based on their **poster images** and **titles**. Given the subjective and multi-label nature of genre classification, our method integrates both **visual and textual features** to enhance classification accuracy.

## ğŸ“Œ Overview

- ğŸ¯ **Task**: Multi-label genre classification for movies
- ğŸ§¾ **Inputs**: Movie posters (images) and titles (text)
- ğŸ§  **Model**: A custom ResNet-inspired CNN for image processing and a TF-IDF-based fully connected network for titles
- ğŸ—ƒï¸ **Dataset**: 3105 labeled movie samples from IMDB
- ğŸ“ˆ **Metrics**: Precision, Recall, and F1-Score

---

## ğŸ“š Motivation

According to Statista, over **800+ movies** are released annually in North America alone. Manually labeling genres is time-consuming, subjective, and increasingly impractical at scale. This project proposes a deep learning solution to **automate** the genre labelling process using only a filmâ€™s **title and poster**, which are often available at early stages of movie production.

---

## ğŸ“¦ Dataset

The dataset includes:

- **3105 movies** (1950sâ€“2000s)
- **18 genre labels** (multi-label, e.g., Action, Drama, Romance)
- Each movie contains:
  - `title`: e.g., _"The Godfather (1972)"_
  - `poster`: RGB image (resized to 256Ã—256)
  - `genre`: one or more genre labels

ğŸ“¥ [Download Dataset (Google Drive)](https://drive.usercontent.google.com/download?id=1hUqu1mbFeTEfBvl-7fc56fHFfCSzIktD)

---

## ğŸ” Preprocessing

- **Titles**: Lowercased, punctuation and year removed, then encoded via **TF-IDF** (vocab size = 8192)
- **Posters**: Resized to 256Ã—256 pixels, converted to tensors
- **Labels**: One-hot encoded genre vectors

---

## ğŸ§  Model Architecture

We propose a **dual-branch neural architecture**:

### ğŸ“ Title Sub-model
- TF-IDF vector (8192-dim) input
- Two fully connected layers with ReLU, BatchNorm, Dropout
- Outputs genre probabilities

### ğŸ–¼ï¸ Poster Sub-model
- Custom CNN inspired by **ResNet**
- Includes skip connections, BatchNorm, Dropout
- Outputs genre probabilities

### ğŸ”— Fusion
- Outputs from both sub-models are **summed**
- Final prediction is made from the combined logits

---

## ğŸ‹ï¸ Training

- **Epochs**: 50
- **Batch size**: 64
- **Loss function**: *CrossEntropyLoss* (can be improved using `BCEWithLogitsLoss` for multi-label)
- **Optimizer**: Adam (lr=1e-3, weight decay=1e-4)
- **Hardware**: Trained on NVIDIA T4 GPU (16GB), ~30 minutes

---

## ğŸ“Š Evaluation

Evaluated on a hold-out test set using:

| Metric    | Description |
|-----------|-------------|
| **Precision** | % of predicted genres that were correct |
| **Recall**    | % of actual genres that were correctly predicted |
| **F1-score**  | Harmonic mean of Precision and Recall |

Results indicate strong performance on common genres. Edge cases (nuanced or rare genres) remain challenging due to limited data size.

---

## ğŸ§ª Real-world Inference

The model can be tested on real movie titles and poster images using the provided `inference` section.

Example:
```python
input_title = "Avengers: Endgame (2019)"
input_image_path = "./avengerEndgame.jpg"
```

Predicted genres:
```
Action: 0.92
Adventure: 0.81
Sci-Fi: 0.64
```

---

## Resources

- ğŸ“ [Dataset Download (zip)](https://drive.usercontent.google.com/download?id=1hUqu1mbFeTEfBvl-7fc56fHFfCSzIktD)

---

## ğŸ§  Authors
 
- DÆ°Æ¡ng Nguyá»…n Gia Vinh

Vietnam National University, Hanoi â€“ University of Engineering and Technology  

---

## ğŸ“š References

> [1] He et al., â€œDeep Residual Learning for Image Recognitionâ€, CVPR 2016  
> [2] SpÃ¤rck Jones, â€œA Statistical Interpretation of Term Specificityâ€¦â€, Journal of Documentation, 1972  
> [3] Kingma & Ba, â€œAdam: A Method for Stochastic Optimizationâ€, 2014  
> [4] Srivastava et al., â€œDropout: A Simple Way to Prevent Neural Networks from Overfittingâ€, 2014  
> [5] Ioffe & Szegedy, â€œBatch Normalizationâ€, 2015  
> [6] Chu & Guo, â€œMovie Genre Classification using Poster Imagesâ€, MUSA2 2017  
> [7] Narawade et al., â€œMovie Poster Classification into Multiple Genresâ€, ICACC 2021  
> [8] Sung & Chokshi, â€œMovie Genre Classificationâ€, Stanford CS230, 2020

---

## ğŸ“Œ Future Work

- Augment training data with subtitle/synopsis embeddings
- Incorporate pretrained vision transformers (ViT, CLIP)
- Explore prompt-based genre reasoning using multimodal LLMs (e.g., Flamingo, LLaVA)
